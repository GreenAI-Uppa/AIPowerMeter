
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Advanced use &#8212; AI Power Meter  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Dev Documentation" href="modules.html" />
    <link rel="prev" title="Background on power measure" href="../background/background.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="advanced-use">
<h1>Advanced use<a class="headerlink" href="#advanced-use" title="Permalink to this heading">¶</a></h1>
<p>See also the <a class="reference external" href="https://github.com/GreenAI-Uppa/AIPowerMeter/tree/main/examples">example scripts</a> to test the different metrics provided by the library.</p>
<div class="section" id="recorded-fields">
<span id="json"></span><h2>Recorded fields<a class="headerlink" href="#recorded-fields" title="Permalink to this heading">¶</a></h2>
<p>Recordings are logged in a json file and include the power draw and the use of the CPU and GPU for the pids related to your experiment. Some of the recordings are done for each pid related to your experiments: <cite>per_process_metric_name : {… pid_i: v_i, ….}</cite>. However, the monitoring of multiple programs on the same device should be done with care (see <a class="reference internal" href="../background/background.html#multiple"><span class="std std-ref">Measuring multiple programs</span></a>). In the following, we details the different metrics recorded. Unless specified otherwise, the power is logged in Watt.</p>
<p>First you can load the data of an experiment contained in “your_output_folder”
.. code-block:: python</p>
<blockquote>
<div><p>from deep_learning_power_measure.power_measure import experiment, parsers
driver = parsers.JsonParser(‘your_output_folder’)
exp_result = experiment.ExpResults(driver)</p>
</div></blockquote>
<p>From then, you can compute some statistics</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># power consummed by the CPU measured by RAPL of your experiment</span>
<span class="nb">print</span><span class="p">(</span><span class="n">exp_result</span><span class="o">.</span><span class="n">total_</span><span class="p">(</span><span class="s2">&quot;rel_intel_power&quot;</span><span class="p">))</span>
<span class="c1"># duration of your experiments</span>
<span class="n">d</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="nb">print</span><span class="p">(</span><span class="n">exp_result</span><span class="o">.</span><span class="n">get_duration</span><span class="p">())</span>
</pre></div>
</div>
<p>To check the list of available metrics (might depend on your setup):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">exp_result</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Available metrics :</span>
<span class="go">CPU</span>
<span class="go">  per_process_mem_use_abs,per_process_cpu_uses,per_process_mem_use_percent,intel_power,psys_power,uncore_power,per_process_cpu_power,total_cpu_power,per_process_mem_use_uss</span>
<span class="go">GPU</span>
<span class="go">  nvidia_draw_absolute,nvidia_attributable_power,nvidia_mem_use,nvidia_sm_use,per_gpu_power_draw,per_gpu_attributable_power,per_gpu_estimated_attributable_utilization</span>
<span class="go">Experiments</span>
<span class="go">  nvidia_draw_absolute,nvidia_attributable_power,nvidia_mem_use,nvidia_sm_use,per_gpu_power_draw,per_gpu_attributable_power,per_gpu_estimated_attributable_utilization</span>
</pre></div>
</div>
<p>Below are the definitions of these metrics:</p>
<p><strong>CPU use</strong></p>
<ul class="simple">
<li><p><cite>per_process_mem_use_abs</cite> : RAM PSS Memory usage for each recorded process in bytes*</p></li>
<li><p><cite>per_process_mem_use_percent</cite> : RAM PSS Memory usage for each recorded process in percentage of the overall memory usage*</p></li>
<li><p><cite>per_process_mem_use_uss</cite> : RAM  USS Memory usage for each recorded process*</p></li>
<li><p><cite>per_process_cpu_uses</cite> : Percentage of CPU usage for each process, relatively to the general CPU usage.</p></li>
<li><p><cite>cpu_uses</cite>: percentage of cpu clock used by this pid during the recording.</p></li>
<li><p><cite>mem_use_abs</cite>: Number of bytes used in the CPU RAM. The recording uses psutil in the background, check: <a class="reference internal" href="modules.html#deep_learning_power_measure.power_measure.rapl_power.get_mem_uses" title="deep_learning_power_measure.power_measure.rapl_power.get_mem_uses"><code class="xref py py-func docutils literal notranslate"><span class="pre">deep_learning_power_measure.power_measure.rapl_power.get_mem_uses()</span></code></a> for more details.</p></li>
<li><p><cite>mem_use_percent</cite>: Relative number of bytes used in the CPU RAM PSS.</p></li>
</ul>
<ul class="simple">
<li><p>For details on the USS and PSS memory, check <a class="reference internal" href="modules.html#deep_learning_power_measure.power_measure.rapl_power.get_mem_uses" title="deep_learning_power_measure.power_measure.rapl_power.get_mem_uses"><code class="xref py py-func docutils literal notranslate"><span class="pre">deep_learning_power_measure.power_measure.rapl_power.get_mem_uses()</span></code></a></p></li>
</ul>
<p><strong>Non GPU Energy consumption</strong></p>
<ul class="simple">
<li><p><cite>intel_power</cite> : total consumptino measured by RAPL</p></li>
<li><p><cite>total_cpu_power</cite>: total consumption measured by RAPL for the CPU</p></li>
<li><p><cite>psys_power</cite>: System on chip consumption</p></li>
<li><p><cite>uncore_power</cite>: other hardware present on the cpu board, for instance, an integrated graphic card. This is NOT the nvidia gpu which is on another board.</p></li>
<li><p><cite>total_cpu_power</cite>: core power consumption.</p></li>
<li><p><cite>per_process_cpu_power</cite> : Essentially :  * intel_power. Should be used with caution (see <a class="reference internal" href="../background/background.html#multiple"><span class="std std-ref">Measuring multiple programs</span></a>)</p></li>
<li><p><cite>per_process_mem_use_uss</cite> : USS memory per CPU in RAM.</p></li>
</ul>
<p>In other words, you have the following relation:</p>
<div class="math notranslate nohighlight">
\[Intel\_power = psys + uncore + total\_cpu\]</div>
<p>For the ram and the core power, we multiply by the cpu and memory use of each pid to get the per process value in the fields <cite>per_process_cpu_power</cite> and <cite>per_process_dram_power</cite>.</p>
<p>Check the <a class="reference internal" href="../background/background.html#rapl"><span class="std std-ref">CPU and RAPL</span></a> section for more details on RAPL domains, and <a class="reference internal" href="modules.html#deep_learning_power_measure.power_measure.rapl_power.get_power" title="deep_learning_power_measure.power_measure.rapl_power.get_power"><code class="xref py py-func docutils literal notranslate"><span class="pre">deep_learning_power_measure.power_measure.rapl_power.get_power()</span></code></a> for implementation details. The support for different power domains varies according to the processor model, our library will ignore not available domains.</p>
<p><strong>GPU use</strong></p>
<ul class="simple">
<li><p><cite>per_gpu_attributable_mem_use</cite> : memory usage for each gpu</p></li>
<li><p><cite>per_gpu_per_pid_utilization_absolute</cite> : absolute % of Streaming Multiprocessor (SM) used per gpu per pid</p></li>
<li><p><cite>per_gpu_absolute_percent_usage</cite> : absolute % of SM used per gpu for the given pid list</p></li>
<li><p><cite>per_gpu_estimated_attributable_utilization</cite> : relative use of SM used per gpu by the experiment</p></li>
</ul>
<p><strong>GPU power</strong></p>
<p>This is done by the nvidia-smi tool supported by the NVML library of nvidia.</p>
<ul class="simple">
<li><p><cite>nvidia_draw_absolute</cite>: the amount of power used by the whole nvidia card and all GPUs.</p></li>
<li><p><cite>per_gpu_power_draw</cite>: the amount of power used by the whole nvidia card for each GPUs</p></li>
<li><p><cite>nvidia_attributable_power</cite> : Total nvidia power consumption attributatble to the processes you recorded. It corresponds to</p></li>
<li><p><cite>per_gpu_attributable_power</cite> : same as <cite>nvidia_attributable_power</cite> but for each gpu</p></li>
</ul>
</div>
<div class="section" id="monitoring-whole-machine-with-prometheus">
<h2>Monitoring whole machine with Prometheus<a class="headerlink" href="#monitoring-whole-machine-with-prometheus" title="Permalink to this heading">¶</a></h2>
<p>The following code will launch the monitoring and a flask app on the port 5001</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deep_learning_power_measure.power_measure</span> <span class="kn">import</span> <span class="n">experiment</span><span class="p">,</span> <span class="n">prometheus_client</span>

<span class="n">driver</span> <span class="o">=</span> <span class="n">prometheus_client</span><span class="o">.</span><span class="n">PrometheusClient</span><span class="p">()</span>
<span class="n">exp</span> <span class="o">=</span> <span class="n">experiment</span><span class="o">.</span><span class="n">Experiment</span><span class="p">(</span><span class="n">driver</span><span class="p">)</span>
<span class="n">exp</span><span class="o">.</span><span class="n">monitor_machine</span><span class="p">(</span><span class="n">period</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>Then, you can launch a prometheus instance</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">./prometheus --config.file=prometheus.yml</span>
</pre></div>
</div>
<p>with a config file which look like the following</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">global:</span>
<span class="go">scrape_interval: 3s</span>

<span class="go">external_labels:</span>
<span class="go">  monitor: &quot;example-app&quot;</span>

<span class="go">rule_files:</span>

<span class="go">scrape_configs:</span>
<span class="go">  - job_name: &quot;flask_test&quot;</span>
<span class="go">    static_configs:</span>
<span class="go">      - targets: [&quot;localhost:5001&quot;]</span>
</pre></div>
</div>
<p>Then visit the following url : <cite>http://localhost:9090/graph</cite></p>
<p>Currently, the following metrics are supported</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[&#39;power_draw_cpu&#39;, &#39;intel_power&#39;,</span>
<span class="go">&#39;mem_used_cpu&#39;, &#39;mem_used_gpu&#39;,</span>
<span class="go">&#39;power_draw_gpu&#39;]</span>
</pre></div>
</div>
</div>
<div class="section" id="model-complexity">
<h2>model complexity<a class="headerlink" href="#model-complexity" title="Permalink to this heading">¶</a></h2>
<p>We use a wrapper for <a class="reference external" href="https://pypi.org/project/torchinfo/">torchinfo</a> to extract statistics about your model, essentially number of parameters and mac operation counts.
To obtain them, add additional parameters:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="o">...</span> <span class="n">the</span> <span class="n">model</span> <span class="n">you</span> <span class="n">are</span> <span class="n">using</span> <span class="k">for</span> <span class="n">your</span> <span class="n">experiment</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="o">...</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">data_point_shape</span><span class="p">)</span>
<span class="n">exp</span> <span class="o">=</span> <span class="n">experiment</span><span class="o">.</span><span class="n">Experiment</span><span class="p">(</span><span class="n">driver</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span><span class="p">)</span>
</pre></div>
</div>
<p>You can log the number of parameters and the number of multiply and add (mac) operations of your model.
Currently, only pytorch is supported.</p>
</div>
<div class="section" id="docker-integration">
<span id="docker"></span><h2>Docker integration<a class="headerlink" href="#docker-integration" title="Permalink to this heading">¶</a></h2>
<p>For the implementation of AIPowerMeter in a docker container, we need to use a special branch of the code because of the behaviour of the command :</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>nvidia-smi pmon
</pre></div>
</div>
<p>An hot fix has been implemented, it forces the tracking of all the GPU processes. It’s then impossible to isolate a process running at the same time than others.</p>
<p>See the github repo <a class="reference external" href="https://github.com/GreenAI-Uppa/docker_AIPM">docker_AIPM</a> for more details. You will also find slides explaining the motivations for the use of Docker images and container.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">AI Power Meter</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../background/background.html">Background on power measure</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Advanced use</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#recorded-fields">Recorded fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="#monitoring-whole-machine-with-prometheus">Monitoring whole machine with Prometheus</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-complexity">model complexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="#docker-integration">Docker integration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Dev Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experiments/experiments.html">Deep learning benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experiments/schneiderbox.html">Machine and Deep Learning Benchmarks with wattmeters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bibliography.html">Bibliography</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="../background/background.html" title="previous chapter">Background on power measure</a></li>
      <li>Next: <a href="modules.html" title="next chapter">Dev Documentation</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, GreenAIUppa.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.3.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/usage/in_details.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>